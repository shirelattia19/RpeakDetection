batch_size: 32
dropout: 0.3
hidden_size: 64
learning_rate: 0.004
num_layers: 2
seq_len: 80
weight: 0.0036
